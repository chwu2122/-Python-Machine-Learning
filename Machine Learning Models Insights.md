Recap for machine learning models Insights

This is a quick recap for Machine Learning for Insights -- Extract human understandable insights from any Machine Learning model from Kaggle.
It covers Permutation Importance, Partial Dependence Plots and SHAP Values. I grouped them together to make it more scalable. Essentially, this makes machine learning models more interpretable.

The notebook is hosted at https://www.kaggle.com/c753833/recap-for-machine-learning-models-insights

I found there are two great resources that dive into Interpretable Machine Learning in more depth.
Book: Interpretable Machine Learning
NoteBook: Interpretable Machine Learning with Python
