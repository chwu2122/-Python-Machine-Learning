
# Recap for machine learning models Insights

The notebook is hosted at https://www.kaggle.com/c753833/recap-for-machine-learning-models-insights

Uploaded the notebook into github for completeness: https://github.com/chwu2122/Python-Machine-Learning/blob/master/Recap%20for%20machine%20learning%20models%20Insights.ipynb


This is a quick recap for [Machine Learning for Insights -- Extract human understandable insights from any Machine Learning model](https://www.kaggle.com/learn/machine-learning-for-insights) from Kaggle.  

It covers Permutation Importance, Partial Dependence Plots and SHAP Values. I grouped them together to make it more scalable. Essentially, this makes machine learning models more interpretable. 

I found there are two great resources that dive into Interpretable Machine Learning in more depth.   
Book: [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)  
NoteBook: [Interpretable Machine Learning with Python](http://savvastjortjoglou.com/intrepretable-machine-learning-nfl-combine.html)


